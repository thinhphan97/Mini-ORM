window.MINI_ORM_EXAMPLE_SOURCES = {
  "examples/sql/01_basic_crud.py": "\"\"\"Basic SQL CRUD example for mini_orm Repository.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import Database, Repository, SQLiteDialect, apply_schema\n\n@dataclass\nclass User:\n    # Auto primary key: mini_orm will set this after insert.\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    email: str = \"\"\n    age: Optional[int] = None\n\ndef main() -> None:\n    # 1) Create DB adapter and repository.\n    conn = sqlite3.connect(\":memory:\")\n    db = Database(conn, SQLiteDialect())\n    repo = Repository[User](db, User)\n\n    try:\n        # 2) Create table from dataclass metadata.\n        apply_schema(db, User)\n\n        # 3) Insert rows.\n        alice = repo.insert(User(email=\"alice@example.com\", age=25))\n        bob = repo.insert(User(email=\"bob@example.com\", age=30))\n        print(\"Inserted:\", alice, bob)\n\n        # 4) Get by PK.\n        fetched = repo.get(alice.id)\n        print(\"Fetched by PK:\", fetched)\n\n        # 5) Update by PK (model instance must include PK).\n        bob.age = 31\n        updated = repo.update(bob)\n        print(\"Updated row count:\", updated)\n\n        # 6) List all rows.\n        print(\"All users:\", repo.list())\n\n        # 7) Delete by PK.\n        deleted = repo.delete(alice)\n        print(\"Deleted row count:\", deleted)\n        print(\"After delete:\", repo.list())\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/02_query_conditions.py": "\"\"\"Query condition examples: where/group/order/limit/offset/count/exists.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import C, Database, OrderBy, Repository, SQLiteDialect, apply_schema\n\n@dataclass\nclass Account:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    email: str = \"\"\n    age: Optional[int] = None\n    role: str = \"user\"\n    active: bool = True\n    deleted_at: Optional[str] = None\n\ndef seed(repo: Repository[Account]) -> None:\n    repo.insert_many(\n        [\n            Account(email=\"alice@example.com\", age=24, role=\"admin\", active=True),\n            Account(email=\"bob@example.com\", age=30, role=\"owner\", active=True),\n            Account(email=\"charlie@example.com\", age=17, role=\"user\", active=True),\n            Account(email=\"dana@sample.com\", age=35, role=\"user\", active=False),\n            Account(email=\"erin@example.com\", age=None, role=\"auditor\", active=True),\n            Account(\n                email=\"frank@example.com\",\n                age=40,\n                role=\"user\",\n                active=False,\n                deleted_at=\"2026-01-01T00:00:00\",\n            ),\n        ]\n    )\n\ndef main() -> None:\n    conn = sqlite3.connect(\":memory:\")\n    db = Database(conn, SQLiteDialect())\n    repo = Repository[Account](db, Account)\n\n    try:\n        apply_schema(db, Account)\n        seed(repo)\n\n        # One condition.\n        admins = repo.list(where=C.eq(\"role\", \"admin\"))\n        print(\"Admins:\", admins)\n\n        # Multiple conditions in a list => joined with AND.\n        adults_at_example = repo.list(\n            where=[C.ge(\"age\", 18), C.like(\"email\", \"%@example.com\")]\n        )\n        print(\"Adults at @example.com:\", adults_at_example)\n\n        # Grouped condition:\n        # active = true AND (role = admin OR role = owner) AND NOT deleted.\n        privileged_active = repo.list(\n            where=C.and_(\n                C.eq(\"active\", True),\n                C.or_(C.eq(\"role\", \"admin\"), C.eq(\"role\", \"owner\")),\n                C.not_(C.is_not_null(\"deleted_at\")),\n            ),\n            order_by=[OrderBy(\"id\")],\n        )\n        print(\"Privileged active accounts:\", privileged_active)\n\n        # IN condition.\n        in_roles = repo.list(\n            where=C.in_(\"role\", [\"admin\", \"auditor\"]),\n            order_by=[OrderBy(\"role\"), OrderBy(\"id\")],\n        )\n        print(\"IN role(admin, auditor):\", in_roles)\n\n        # NULL / NOT NULL checks.\n        with_null_age = repo.list(where=C.is_null(\"age\"))\n        with_deleted_at = repo.list(where=C.is_not_null(\"deleted_at\"))\n        print(\"Rows where age IS NULL:\", with_null_age)\n        print(\"Rows where deleted_at IS NOT NULL:\", with_deleted_at)\n\n        # Basic operators: ne, lt, le, gt.\n        not_users = repo.list(where=C.ne(\"role\", \"user\"))\n        age_lt_30 = repo.list(where=C.lt(\"age\", 30))\n        age_le_30 = repo.list(where=C.le(\"age\", 30))\n        age_gt_30 = repo.list(where=C.gt(\"age\", 30))\n        print(\"role <> user:\", not_users)\n        print(\"age < 30:\", age_lt_30)\n        print(\"age <= 30:\", age_le_30)\n        print(\"age > 30:\", age_gt_30)\n\n        # Sorting + pagination.\n        page = repo.list(\n            where=C.like(\"email\", \"%@example.com\"),\n            order_by=[OrderBy(\"age\", desc=True), OrderBy(\"id\", desc=False)],\n            limit=2,\n            offset=1,\n        )\n        print(\"Paged rows (limit=2, offset=1):\", page)\n\n        # Count / exists utilities.\n        count_example = repo.count(where=C.like(\"email\", \"%@example.com\"))\n        has_minor = repo.exists(where=C.lt(\"age\", 18))\n        has_superadmin = repo.exists(where=C.eq(\"role\", \"superadmin\"))\n        print(\"Count @example.com:\", count_example)\n        print(\"Exists minor:\", has_minor)\n        print(\"Exists superadmin:\", has_superadmin)\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/03_repository_utilities.py": "\"\"\"Repository utility APIs: insert_many/update_where/delete_where/get_or_create.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import C, Database, Repository, SQLiteDialect, apply_schema\n\n@dataclass\nclass Product:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    sku: str = field(default=\"\", metadata={\"unique_index\": True})\n    category: str = \"\"\n    price: float = 0.0\n    stock: int = 0\n\n    def __post_init__(self) -> None:\n        if not isinstance(self.sku, str) or not self.sku.strip():\n            raise ValueError(\"sku must be a non-empty string.\")\n\ndef main() -> None:\n    conn = sqlite3.connect(\":memory:\")\n    db = Database(conn, SQLiteDialect())\n    repo = Repository[Product](db, Product)\n\n    try:\n        apply_schema(db, Product)\n\n        # insert_many is a convenience wrapper that calls insert for each object.\n        inserted = repo.insert_many(\n            [\n                Product(sku=\"MUG-BLACK\", category=\"kitchen\", price=9.9, stock=50),\n                Product(sku=\"MUG-WHITE\", category=\"kitchen\", price=10.9, stock=80),\n                Product(sku=\"BOOK-ORM\", category=\"books\", price=29.9, stock=20),\n            ]\n        )\n        print(\"Inserted products:\", inserted)\n\n        # count / exists utility methods.\n        print(\"Count all:\", repo.count())\n        print(\"Exists books:\", repo.exists(where=C.eq(\"category\", \"books\")))\n        print(\"Exists toys:\", repo.exists(where=C.eq(\"category\", \"toys\")))\n\n        # update_where updates all rows matching the where expression.\n        affected_update = repo.update_where(\n            {\"price\": 12.5},\n            where=C.eq(\"category\", \"kitchen\"),\n        )\n        print(\"update_where affected rows:\", affected_update)\n        print(\"After bulk update:\", repo.list(where=C.eq(\"category\", \"kitchen\")))\n\n        # delete_where deletes all rows matching the where expression.\n        affected_delete = repo.delete_where(where=C.lt(\"stock\", 30))\n        print(\"delete_where affected rows:\", affected_delete)\n        print(\"After bulk delete:\", repo.list())\n\n        # get_or_create: first call creates, second call reuses.\n        first, created_first = repo.get_or_create(\n            lookup={\"sku\": \"LAMP-RED\"},\n            defaults={\"category\": \"home\", \"price\": 49.9, \"stock\": 10},\n        )\n        second, created_second = repo.get_or_create(\n            lookup={\"sku\": \"LAMP-RED\"},\n            defaults={\"category\": \"ignored\", \"price\": 999.0, \"stock\": 0},\n        )\n        print(\"get_or_create first:\", first, \"created=\", created_first)\n        print(\"get_or_create second:\", second, \"created=\", created_second)\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/04_schema_and_indexes.py": "\"\"\"Schema and index generation/apply examples.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import (\n    Database,\n    SQLiteDialect,\n    apply_schema,\n    create_index_sql,\n    create_indexes_sql,\n    create_schema_sql,\n    create_table_sql,\n)\n\n@dataclass\nclass Article:\n    # PK + auto for SQLite integer primary key behavior.\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n\n    # Field-level index metadata.\n    slug: str = field(default=\"\", metadata={\"unique_index\": True, \"index_name\": \"uidx_article_slug\"})\n    author_id: int = field(default=0, metadata={\"index\": True})\n    title: str = \"\"\n    published: bool = False\n\n    # Multi-column index declarations.\n    __indexes__ = [\n        (\"published\", \"author_id\"),\n        {\"columns\": (\"author_id\", \"title\"), \"name\": \"idx_article_author_title\"},\n    ]\n\ndef print_sql_preview(dialect: SQLiteDialect) -> None:\n    print(\"\\n--- create_table_sql ---\")\n    print(create_table_sql(Article, dialect))\n\n    print(\"\\n--- create_index_sql (single column) ---\")\n    print(create_index_sql(Article, dialect, \"title\"))\n\n    print(\"\\n--- create_indexes_sql (from metadata + __indexes__) ---\")\n    for sql in create_indexes_sql(Article, dialect):\n        print(sql)\n\n    print(\"\\n--- create_schema_sql (table + indexes) ---\")\n    for sql in create_schema_sql(Article, dialect):\n        print(sql)\n\ndef main() -> None:\n    dialect = SQLiteDialect()\n    print_sql_preview(dialect)\n\n    conn = sqlite3.connect(\":memory:\")\n    db = Database(conn, dialect)\n    try:\n        # apply_schema executes table + indexes in one transaction.\n        statements = apply_schema(db, Article, if_not_exists=True)\n        print(\"\\nApplied statements count:\", len(statements))\n\n        # Calling again with if_not_exists=True is safe and idempotent.\n        apply_schema(db, Article, if_not_exists=True)\n        print(\"Applied schema twice safely with if_not_exists=True\")\n\n        # Inspect created indexes in SQLite.\n        index_rows = conn.execute(\"PRAGMA index_list('article');\").fetchall()\n        index_names = [row[1] for row in index_rows]\n        print(\"SQLite index names:\", index_names)\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/05_validation_and_error_cases.py": "\"\"\"Validation and error case examples for SQL repository and schema APIs.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import C, Database, Repository, SQLiteDialect, apply_schema\n\nclass PlainModel:\n    \"\"\"Intentionally not a dataclass.\"\"\"\n\n@dataclass\nclass NoPkModel:\n    email: str = \"\"\n\n@dataclass\nclass MultiPkModel:\n    id1: int = field(default=0, metadata={\"pk\": True})\n    id2: int = field(default=0, metadata={\"pk\": True})\n\n@dataclass\nclass User:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    email: str = \"\"\n    age: Optional[int] = None\n\n@dataclass\nclass OnlyPkModel:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n\ndef expect_error(label: str, fn) -> None:  # noqa: ANN001\n    try:\n        fn()\n    except Exception as exc:  # noqa: BLE001\n        print(f\"[OK] {label}: {type(exc).__name__}: {exc}\")\n    else:\n        print(f\"[UNEXPECTED] {label}: no exception raised\")\n\ndef main() -> None:\n    conn = sqlite3.connect(\":memory:\")\n    db = Database(conn, SQLiteDialect())\n    repo = Repository[User](db, User)\n\n    try:\n        apply_schema(db, User)\n        apply_schema(db, OnlyPkModel)\n\n        # Model-level validations.\n        expect_error(\"Repository requires dataclass model\", lambda: Repository(db, PlainModel))\n        expect_error(\"Model must have PK\", lambda: Repository(db, NoPkModel))\n        expect_error(\"Model must have exactly one PK\", lambda: Repository(db, MultiPkModel))\n\n        # Seed one row for update/delete and where validations.\n        row = repo.insert(User(email=\"seed@example.com\", age=20))\n\n        # update/delete require PK on object.\n        expect_error(\"update requires PK\", lambda: repo.update(User(email=\"x@example.com\", age=1)))\n        expect_error(\"delete requires PK\", lambda: repo.delete(User(email=\"x@example.com\", age=1)))\n\n        # list validates pagination values.\n        expect_error(\"limit must be > 0\", lambda: repo.list(limit=0))\n        expect_error(\"offset must be >= 0\", lambda: repo.list(offset=-1))\n\n        # update_where validations.\n        expect_error(\"update_where empty values\", lambda: repo.update_where({}, where=C.eq(\"id\", row.id)))\n        expect_error(\"update_where missing where\", lambda: repo.update_where({\"age\": 30}, where=None))\n        expect_error(\"update_where unknown column\", lambda: repo.update_where({\"unknown\": 1}, where=C.eq(\"id\", row.id)))\n        expect_error(\"update_where cannot update PK\", lambda: repo.update_where({\"id\": 999}, where=C.eq(\"id\", row.id)))\n\n        # delete_where validation.\n        expect_error(\"delete_where missing where\", lambda: repo.delete_where(where=None))\n\n        # get_or_create validation.\n        expect_error(\"get_or_create requires non-empty lookup\", lambda: repo.get_or_create(lookup={}))\n\n        # Updating a model with only PK and no writable columns is rejected.\n        only_pk_repo = Repository[OnlyPkModel](db, OnlyPkModel)\n        only = only_pk_repo.insert(OnlyPkModel())\n        expect_error(\"update rejected when no writable columns\", lambda: only_pk_repo.update(only))\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/06_dialect_preview.py": "\"\"\"Show SQL generation differences across SQLite/Postgres/MySQL dialects.\"\"\"\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import C, OrderBy, create_table_sql\nfrom mini_orm.core.query_builder import append_limit_offset, compile_order_by, compile_where\nfrom mini_orm.ports.db_api.dialects import MySQLDialect, PostgresDialect, SQLiteDialect\n\n@dataclass\nclass PreviewUser:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    email: str = \"\"\n    age: Optional[int] = None\n\ndef show_for_dialect(name: str, dialect) -> None:  # noqa: ANN001\n    print(f\"\\n===== {name} =====\")\n\n    where = C.and_(\n        C.like(\"email\", \"%@example.com\"),\n        C.or_(C.ge(\"age\", 18), C.is_null(\"age\")),\n        C.not_(C.eq(\"email\", \"blocked@example.com\")),\n    )\n    order_by = [OrderBy(\"age\", desc=True), OrderBy(\"id\")]\n\n    where_fragment = compile_where(where, dialect)\n    order_fragment = compile_order_by(order_by, dialect)\n    sql = f\"SELECT * FROM {dialect.q('previewuser')}{where_fragment.sql}{order_fragment}\"\n    sql, params = append_limit_offset(sql, where_fragment.params, limit=5, offset=10, dialect=dialect)\n\n    print(\"SQL:\", sql)\n    print(\"Params:\", params)\n    print(\"DDL:\", create_table_sql(PreviewUser, dialect))\n\ndef main() -> None:\n    show_for_dialect(\"SQLiteDialect\", SQLiteDialect())\n    show_for_dialect(\"PostgresDialect\", PostgresDialect())\n    show_for_dialect(\"MySQLDialect\", MySQLDialect())\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/07_relations_create_and_query.py": "\"\"\"Relation example: create nested records and query with included relations.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import C, Database, OrderBy, Repository, SQLiteDialect\n\n@dataclass\nclass Author:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    name: str = \"\"\n\n@dataclass\nclass Post:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    author_id: Optional[int] = field(\n        default=None,\n        metadata={\n            \"fk\": (Author, \"id\"),\n            \"relation\": \"author\",\n            \"related_name\": \"posts\",\n        },\n    )\n    title: str = \"\"\n    published: bool = False\n\ndef main() -> None:\n    conn = sqlite3.connect(\":memory:\")\n    conn.execute(\"PRAGMA foreign_keys = ON;\")\n    db = Database(conn, SQLiteDialect())\n    author_repo = Repository[Author](db, Author, auto_schema=True)\n    post_repo = Repository[Post](db, Post, auto_schema=True)\n\n    try:\n        # 1) Create author with related posts in one call (has_many).\n        alice = Author(name=\"Alice\")\n        author_repo.create(\n            alice,\n            relations={\n                \"posts\": [\n                    Post(title=\"Mini ORM Basics\", published=True),\n                    Post(title=\"Mini ORM Relations\", published=False),\n                ]\n            },\n        )\n        print(\"Created author with posts:\", alice)\n\n        # 2) Create one post with nested author (belongs_to).\n        bonus_post = Post(title=\"Belongs To Flow\", published=True)\n        post_repo.create(\n            bonus_post,\n            relations={\"author\": Author(name=\"Bob\")},\n        )\n        print(\"Created post with nested author:\", bonus_post)\n\n        # 3) Fetch one author with included posts.\n        author_with_posts = author_repo.get_related(alice.id, include=[\"posts\"])\n        if author_with_posts is not None:\n            print(\"Author:\", author_with_posts.obj)\n            print(\"Author posts:\", author_with_posts.relations[\"posts\"])\n\n        # 4) List posts with included author.\n        posts_with_author = post_repo.list_related(\n            include=[\"author\"],\n            where=C.eq(\"published\", True),\n            order_by=[OrderBy(\"id\")],\n        )\n        print(\"Published posts with author:\")\n        for item in posts_with_author:\n            print(\"-\", item.obj.title, \"| author:\", item.relations[\"author\"])\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/08_codec_serialize_deserialize.py": "\"\"\"Enum/JSON codec serialize-deserialize example for SQL repository.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any, Optional\n\nfrom mini_orm import C, Database, Repository, SQLiteDialect, apply_schema\n\nclass ArticleStatus(str, Enum):\n    DRAFT = \"draft\"\n    PUBLISHED = \"published\"\n\n@dataclass\nclass Article:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    title: str = \"\"\n    status: ArticleStatus = ArticleStatus.DRAFT\n    meta: dict[str, Any] = field(default_factory=dict)\n    tags: list[str] = field(default_factory=list)\n    extra: Any = field(default_factory=dict, metadata={\"codec\": \"json\"})\n\ndef main() -> None:\n    conn = sqlite3.connect(\":memory:\")\n    db = Database(conn, SQLiteDialect())\n    repo = Repository[Article](db, Article)\n\n    try:\n        apply_schema(db, Article)\n\n        # Input object: rich Python values.\n        inserted = repo.insert(\n            Article(\n                title=\"Codec demo\",\n                status=ArticleStatus.PUBLISHED,\n                meta={\"views\": 100, \"featured\": True},\n                tags=[\"orm\", \"codec\"],\n                extra={\"author\": {\"name\": \"Alice\"}},\n            )\n        )\n        print(\"Inserted model:\", inserted)\n\n        # Raw DB values after serialize phase.\n        raw = conn.execute(\n            'SELECT \"status\", \"meta\", \"tags\", \"extra\" FROM \"article\" WHERE \"id\" = ?;',\n            (inserted.id,),\n        ).fetchone()\n        print(\"Raw DB row (serialized):\", raw)\n\n        # Output model after deserialize phase.\n        loaded = repo.get(inserted.id)\n        print(\"Loaded model (deserialized):\", loaded)\n        print(\n            \"Loaded value types:\",\n            type(loaded.status).__name__,\n            type(loaded.meta).__name__,\n            type(loaded.tags).__name__,\n            type(loaded.extra).__name__,\n        )\n\n        # Query input also supports codec conversion (Enum in WHERE).\n        matched = repo.list(where=C.eq(\"status\", ArticleStatus.PUBLISHED))\n        print(\"Matched by enum status:\", matched)\n\n        # Update input with JSON payload; read back as Python dict.\n        repo.update_where(\n            {\"meta\": {\"views\": 101, \"featured\": False}},\n            where=C.eq(\"status\", ArticleStatus.PUBLISHED),\n        )\n        print(\"After update_where:\", repo.get(inserted.id))\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/09_async_basic_crud.py": "from __future__ import annotations\n\nimport asyncio\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import C, AsyncDatabase, AsyncRepository, SQLiteDialect\n\n@dataclass\nclass User:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    email: str = \"\"\n    age: Optional[int] = None\n\nasync def main() -> None:\n    conn = sqlite3.connect(\":memory:\")\n    try:\n        db = AsyncDatabase(conn, SQLiteDialect())\n        repo = AsyncRepository[User](db, User, auto_schema=True)\n\n        alice = await repo.insert(User(email=\"alice@example.com\", age=20))\n        print(\"inserted:\", alice)\n\n        found = await repo.get(alice.id)\n        print(\"found:\", found)\n        if found is None:\n            raise RuntimeError(\"Inserted user was not found.\")\n\n        found.age = 21\n        await repo.update(found)\n        print(\"after update:\", await repo.get(found.id))\n\n        rows = await repo.list(\n            where=C.like(\"email\", \"%@example.com\"),\n        )\n        print(\"rows:\", rows)\n\n        await repo.delete(found)\n        print(\"count after delete:\", await repo.count())\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
  "examples/sql/10_async_postgres_example.py": "\"\"\"Async Postgres example (optional dependency + running server).\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport importlib\nimport os\nfrom dataclasses import dataclass, field\nfrom typing import Any, Optional\n\nfrom mini_orm import (\n    AsyncDatabase,\n    AsyncRepository,\n    PostgresDialect,\n)\n\ndef _load_connect() -> Any:\n    for module_name in (\"psycopg\", \"psycopg2\"):\n        try:\n            module = importlib.import_module(module_name)\n        except (ModuleNotFoundError, ImportError):\n            continue\n        connect = getattr(module, \"connect\", None)\n        if connect is not None:\n            return connect\n    return None\n\n@dataclass\nclass User:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    email: str = field(default=\"\")\n    age: Optional[int] = None\n\nasync def main() -> None:\n    connect = _load_connect()\n    if connect is None:\n        print(\"Postgres async example skipped: psycopg/psycopg2 not installed.\")\n        print(\"Install dependency: pip install psycopg\")\n        return\n\n    password = os.getenv(\n        \"MINI_ORM_PG_PASSWORD\",\n        os.getenv(\"PGPASSWORD\", os.getenv(\"POSTGRES_PASSWORD\", \"password\")),\n    )\n    params = {\n        \"host\": os.getenv(\"MINI_ORM_PG_HOST\", os.getenv(\"PGHOST\", \"localhost\")),\n        \"port\": int(os.getenv(\"MINI_ORM_PG_PORT\", os.getenv(\"PGPORT\", \"5432\"))),\n        \"user\": os.getenv(\"MINI_ORM_PG_USER\", os.getenv(\"PGUSER\", \"postgres\")),\n        \"password\": password,\n        \"dbname\": os.getenv(\"MINI_ORM_PG_DATABASE\", os.getenv(\"PGDATABASE\", \"postgres\")),\n    }\n\n    try:\n        conn = connect(**params)\n    except Exception as exc:  # noqa: BLE001 - pragmatic cross-driver OperationalError handling (psycopg/psycopg2)\n        print(\"Postgres async example skipped:\", exc)\n        return\n\n    try:\n        # This wraps a synchronous psycopg/psycopg2 connection in AsyncDatabase.\n        # For true async network I/O with psycopg3, use psycopg.AsyncConnection.connect(...).\n        db = AsyncDatabase(conn, PostgresDialect())\n        repo = AsyncRepository[User](db, User, auto_schema=True)\n\n        async with db.transaction():\n            await db.execute('DROP TABLE IF EXISTS \"user\";')\n\n        async with db.transaction():\n            alice = await repo.insert(User(email=\"alice@example.com\", age=25))\n            bob = await repo.insert(User(email=\"bob@example.com\", age=30))\n            bob.age = 31\n            await repo.update(bob)\n\n        print(\"Inserted:\", alice, bob)\n        print(\"All users:\", await repo.list())\n\n        async with db.transaction():\n            await repo.delete(alice)\n        print(\"After delete:\", await repo.list())\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
  "examples/sql/11_async_mysql_example.py": "\"\"\"Async MySQL example (optional dependency + running server).\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport importlib\nimport os\nimport re\nfrom dataclasses import dataclass, field\nfrom typing import Any, Optional\n\nfrom mini_orm import AsyncDatabase, AsyncRepository, MySQLDialect\n\ndef _load_mysql_driver() -> tuple[str, Any] | tuple[None, None]:\n    for module_name in (\"MySQLdb\", \"pymysql\", \"mysql.connector\"):\n        try:\n            module = importlib.import_module(module_name)\n        except ImportError:\n            continue\n        connect = getattr(module, \"connect\", None)\n        if connect is not None:\n            return module_name, connect\n    return None, None\n\ndef _mysql_connect(\n    *,\n    driver_name: str,\n    connect: Any,\n    host: str,\n    port: int,\n    user: str,\n    password: str,\n    database: str,\n) -> Any:\n    if driver_name == \"MySQLdb\":\n        return connect(\n            host=host,\n            port=port,\n            user=user,\n            passwd=password,\n            db=database,\n            charset=\"utf8mb4\",\n        )\n    if driver_name == \"pymysql\":\n        return connect(\n            host=host,\n            port=port,\n            user=user,\n            password=password,\n            db=database,\n            charset=\"utf8mb4\",\n        )\n    return connect(  # mysql.connector\n        host=host,\n        port=port,\n        user=user,\n        password=password,\n        database=database,\n    )\n\n@dataclass\nclass User:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    email: str = \"\"\n    age: Optional[int] = None\n\nasync def main() -> None:\n    driver_name, connect = _load_mysql_driver()\n    if connect is None:\n        print(\"MySQL async example skipped: no mysql driver installed.\")\n        print(\"Install one of: pip install mysqlclient / pymysql / mysql-connector-python\")\n        return\n\n    host = os.getenv(\"MINI_ORM_MYSQL_HOST\", os.getenv(\"MYSQL_HOST\", \"localhost\"))\n    port = int(os.getenv(\"MINI_ORM_MYSQL_PORT\", os.getenv(\"MYSQL_PORT\", \"3306\")))\n    user = os.getenv(\"MINI_ORM_MYSQL_USER\", os.getenv(\"MYSQL_USER\", \"root\"))\n    password = os.getenv(\n        \"MINI_ORM_MYSQL_PASSWORD\",\n        os.getenv(\"MYSQL_ROOT_PASSWORD\", os.getenv(\"MYSQL_PASSWORD\", \"password\")),\n    )\n    database = os.getenv(\n        \"MINI_ORM_MYSQL_DATABASE\",\n        os.getenv(\"MYSQL_DATABASE\", \"mini_orm_test\"),\n    )\n    if not re.fullmatch(r\"[A-Za-z0-9_]+\", database):\n        raise ValueError(\n            \"Invalid MINI_ORM_MYSQL_DATABASE/MYSQL_DATABASE value. \"\n            \"Use only letters, numbers, and underscores.\"\n        )\n    bootstrap_db = os.getenv(\"MINI_ORM_MYSQL_BOOTSTRAP_DB\", \"mysql\")\n\n    try:\n        bootstrap_conn = _mysql_connect(\n            driver_name=driver_name,  # type: ignore[arg-type]\n            connect=connect,\n            host=host,\n            port=port,\n            user=user,\n            password=password,\n            database=bootstrap_db,\n        )\n        cur = None\n        try:\n            cur = bootstrap_conn.cursor()\n            cur.execute(f\"CREATE DATABASE IF NOT EXISTS `{database}`;\")\n            bootstrap_conn.commit()\n        finally:\n            if cur is not None:\n                cur.close()\n            bootstrap_conn.close()\n\n        conn = _mysql_connect(\n            driver_name=driver_name,  # type: ignore[arg-type]\n            connect=connect,\n            host=host,\n            port=port,\n            user=user,\n            password=password,\n            database=database,\n        )\n    # Intentional broad catch for demo portability across mysqlclient/pymysql/mysql-connector.\n    # Production code should catch driver-specific exceptions.\n    except Exception as exc:  # noqa: BLE001\n        print(\"MySQL async example skipped:\", exc)\n        return\n\n    try:\n        db = AsyncDatabase(conn, MySQLDialect())\n        repo = AsyncRepository[User](db, User, auto_schema=True)\n\n        async with db.transaction():\n            await db.execute(\"DROP TABLE IF EXISTS `user`;\")\n\n        async with db.transaction():\n            alice = await repo.insert(User(email=\"alice@example.com\", age=25))\n            bob = await repo.insert(User(email=\"bob@example.com\", age=30))\n            bob.age = 31\n            await repo.update(bob)\n\n        print(\"Inserted:\", alice, bob)\n        print(\"All users:\", await repo.list())\n\n        async with db.transaction():\n            await repo.delete(alice)\n        print(\"After delete:\", await repo.list())\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
  "examples/sql/12_unified_repository.py": "\"\"\"Unified repository example: one hub object for multiple model classes.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import Database, OrderBy, SQLiteDialect, UnifiedRepository\n\n@dataclass\nclass Author:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    name: str = \"\"\n\n@dataclass\nclass Post:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    author_id: Optional[int] = field(\n        default=None,\n        metadata={\"fk\": (Author, \"id\"), \"relation\": \"author\", \"related_name\": \"posts\"},\n    )\n    title: str = \"\"\n\ndef main() -> None:\n    conn = sqlite3.connect(\":memory:\")\n    try:\n        db = Database(conn, SQLiteDialect())\n        hub = UnifiedRepository(db, auto_schema=True, require_registration=True)\n        hub.register_many([Author, Post])\n\n        author = hub.create(\n            Author(name=\"Alice\"),\n            relations={\"posts\": [Post(title=\"P1\"), Post(title=\"P2\")]},\n        )\n        print(\"Created author:\", author)\n        print(\"Post count:\", hub.count(Post))\n\n        related = hub.get_related(Author, author.id, include=[\"posts\"])\n        print(\"Author with posts:\", related)\n\n        posts = hub.list_related(Post, include=[\"author\"], order_by=[OrderBy(\"id\")])\n        print(\"Posts with author:\", posts)\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/13_async_unified_repository.py": "\"\"\"Async unified repository example: one async hub for multiple model classes.\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import (\n    AsyncDatabase,\n    AsyncUnifiedRepository,\n    OrderBy,\n    SQLiteDialect,\n)\n\n@dataclass\nclass Author:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    name: str = \"\"\n\n@dataclass\nclass Post:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    author_id: Optional[int] = field(\n        default=None,\n        metadata={\"fk\": (Author, \"id\"), \"relation\": \"author\", \"related_name\": \"posts\"},\n    )\n    title: str = \"\"\n\nasync def main() -> None:\n    conn = sqlite3.connect(\":memory:\")\n    try:\n        db = AsyncDatabase(conn, SQLiteDialect())\n        hub = AsyncUnifiedRepository(db, auto_schema=True, require_registration=True)\n        await hub.register_many([Author, Post])\n\n        author = await hub.create(\n            Author(name=\"Alice\"),\n            relations={\"posts\": [Post(title=\"P1\"), Post(title=\"P2\")]},\n        )\n        print(\"Created author:\", author)\n        print(\"Post count:\", await hub.count(Post))\n\n        related = await hub.get_related(Author, author.id, include=[\"posts\"])\n        print(\"Author with posts:\", related)\n\n        posts = await hub.list_related(Post, include=[\"author\"], order_by=[OrderBy(\"id\")])\n        print(\"Posts with author:\", posts)\n    finally:\n        conn.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
  "examples/sql/14_validated_model.py": "\"\"\"Validated dataclass model example (pydantic-like basic checks).\"\"\"\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass, field\n\nfrom mini_orm import ValidatedModel, ValidationError\n\n@dataclass\nclass CreateUserInput(ValidatedModel):\n    email: str = field(\n        default=\"\",\n        metadata={\n            \"non_empty\": True,\n            \"pattern\": r\"[^@]+@[^@]+\\.[^@]+\",\n        },\n    )\n    age: int = field(default=0, metadata={\"ge\": 0, \"le\": 130})\n\ndef main() -> None:\n    ok = CreateUserInput(email=\"alice@example.com\", age=25)\n    print(\"Valid input:\", ok)\n\n    try:\n        CreateUserInput(email=\"bad-email\", age=-2)\n    except ValidationError as exc:\n        print(\"Validation error:\", exc)\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/15_validated_repository_sqlite.py": "\"\"\"ValidatedModel + SQLite Repository integration example.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import (\n    Database,\n    PoolConnector,\n    Repository,\n    SQLiteDialect,\n    ValidationError,\n    ValidatedModel,\n)\n\n@dataclass\nclass Customer(ValidatedModel):\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    email: str = field(\n        default=\"\",\n        metadata={\n            \"unique_index\": True,\n            \"non_empty\": True,\n            \"pattern\": r\"[^@]+@[^@]+\\.[^@]+\",\n        },\n    )\n    full_name: str = field(default=\"\", metadata={\"non_empty\": True, \"min_len\": 2})\n    age: int = field(default=0, metadata={\"ge\": 13, \"le\": 120})\n\ndef create_customer(\n    repo: Repository[Customer],\n    *,\n    email: str,\n    full_name: str,\n    age: int,\n) -> None:\n    try:\n        created = repo.insert(\n            Customer(\n                email=email,\n                full_name=full_name,\n                age=age,\n            )\n        )\n    except ValidationError as exc:\n        print(f\"Rejected input for {email!r}: {exc}\")\n        return\n\n    print(\"Created:\", created)\n\ndef main() -> None:\n    pool = PoolConnector(\n        sqlite3.connect,\n        \"file:validated_repo?mode=memory&cache=shared\",\n        uri=True,\n        check_same_thread=False,\n        max_size=4,\n    )\n    db = Database(pool, SQLiteDialect())\n    try:\n        # auto_schema=True keeps the first-use flow simple for users.\n        repo = Repository[Customer](db, Customer, auto_schema=True)\n\n        create_customer(\n            repo,\n            email=\"alice@example.com\",\n            full_name=\"Alice\",\n            age=22,\n        )\n        create_customer(\n            repo,\n            email=\"not-an-email\",\n            full_name=\"A\",\n            age=10,\n        )\n\n        all_customers = repo.list()\n        print(\"Stored customers:\", all_customers)\n    finally:\n        db.close(close_pool=True)\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/16_postgres_pgvector_integration.py": "\"\"\"PostgreSQL integration example: SQL Repository + PgVectorStore.\"\"\"\n\nfrom __future__ import annotations\n\nimport importlib\nimport os\nfrom dataclasses import dataclass, field\nfrom typing import Any, Optional\n\nfrom mini_orm import (\n    Database,\n    PgVectorStore,\n    PostgresDialect,\n    Repository,\n    VectorMetric,\n    VectorRecord,\n    VectorRepository,\n)\n\ndef _load_connect() -> Any:\n    for module_name in (\"psycopg\", \"psycopg2\"):\n        try:\n            module = importlib.import_module(module_name)\n        except (ModuleNotFoundError, ImportError):\n            continue\n        connect = getattr(module, \"connect\", None)\n        if connect is not None:\n            return connect\n    return None\n\n@dataclass\nclass Document:\n    __table__ = \"pgvector_docs\"\n\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    title: str = field(default=\"\")\n    category: str = field(default=\"\")\n\ndef main() -> None:\n    connect = _load_connect()\n    if connect is None:\n        print(\"Integration example skipped: psycopg/psycopg2 not installed.\")\n        print(\"Install dependency: pip install psycopg\")\n        return\n\n    password = os.getenv(\n        \"MINI_ORM_PG_PASSWORD\",\n        os.getenv(\"PGPASSWORD\", os.getenv(\"POSTGRES_PASSWORD\", \"password\")),\n    )\n    params = {\n        \"host\": os.getenv(\"MINI_ORM_PG_HOST\", os.getenv(\"PGHOST\", \"localhost\")),\n        \"port\": int(os.getenv(\"MINI_ORM_PG_PORT\", os.getenv(\"PGPORT\", \"5432\"))),\n        \"user\": os.getenv(\"MINI_ORM_PG_USER\", os.getenv(\"PGUSER\", \"postgres\")),\n        \"password\": password,\n        \"dbname\": os.getenv(\"MINI_ORM_PG_DATABASE\", os.getenv(\"PGDATABASE\", \"postgres\")),\n    }\n\n    try:\n        conn = connect(**params)\n    except Exception as exc:  # noqa: BLE001 - pragmatic cross-driver OperationalError handling\n        print(\"Integration example skipped:\", exc)\n        return\n\n    db = Database(conn, PostgresDialect())\n    try:\n        sql_repo = Repository[Document](db, Document, auto_schema=True)\n        vector_store = PgVectorStore(db)\n        vector_repo = VectorRepository(\n            vector_store,\n            \"pgvector_doc_embeddings\",\n            dimension=3,\n            metric=VectorMetric.COSINE,\n            auto_create=True,\n            overwrite=True,\n        )\n\n        doc1 = sql_repo.insert(Document(title=\"ORM intro\", category=\"guide\"))\n        doc2 = sql_repo.insert(Document(title=\"API reference\", category=\"docs\"))\n        doc3 = sql_repo.insert(Document(title=\"ORM advanced\", category=\"guide\"))\n\n        vector_repo.upsert(\n            [\n                VectorRecord(str(doc1.id), [1.0, 0.0, 0.0], {\"category\": doc1.category}),\n                VectorRecord(str(doc2.id), [0.0, 1.0, 0.0], {\"category\": doc2.category}),\n                VectorRecord(str(doc3.id), [0.9, 0.1, 0.0], {\"category\": doc3.category}),\n            ]\n        )\n\n        hits = vector_repo.query([1.0, 0.0, 0.0], top_k=3, filters={\"category\": \"guide\"})\n        docs_by_id = {str(doc.id): doc for doc in sql_repo.list()}\n\n        print(\"Vector hits mapped to SQL rows:\")\n        for hit in hits:\n            print(\"-\", docs_by_id.get(hit.id), \"score=\", round(hit.score, 6))\n    finally:\n        db.close()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/17_session_usage.py": "\"\"\"Session example: transaction-scoped sync and async SQL flows.\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom mini_orm import (\n    C,\n    AsyncDatabase,\n    AsyncSession,\n    Database,\n    OrderBy,\n    SQLiteDialect,\n    Session,\n)\n\n\n@dataclass\nclass User:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    email: str = \"\"\n    age: Optional[int] = None\n\n\ndef sync_demo() -> None:\n    print(\"=== Sync Session ===\")\n    conn = sqlite3.connect(\":memory:\")\n    try:\n        db = Database(conn, SQLiteDialect())\n        session = Session(db, auto_schema=True)\n\n        with session:\n            session.insert(User(email=\"alice@example.com\", age=25))\n            session.insert(User(email=\"bob@example.com\", age=30))\n            session.update_where(\n                User,\n                {\"age\": 31},\n                where=C.eq(\"email\", \"bob@example.com\"),\n            )\n\n        rows = session.list(User, order_by=[OrderBy(\"id\")])\n        print(\"After committed transaction:\", rows)\n\n        try:\n            with session.begin():\n                session.insert(User(email=\"rollback@example.com\", age=99))\n                raise RuntimeError(\"force rollback\")\n        except RuntimeError:\n            print(\"Rollback transaction executed as expected.\")\n\n        print(\"Count after rollback:\", session.count(User))\n    finally:\n        conn.close()\n\n\nasync def async_demo() -> None:\n    print(\"\\n=== Async Session ===\")\n    conn = sqlite3.connect(\":memory:\")\n    try:\n        db = AsyncDatabase(conn, SQLiteDialect())\n        session = AsyncSession(db, auto_schema=True)\n\n        async with session:\n            await session.insert(User(email=\"carol@example.com\", age=22))\n            await session.insert(User(email=\"dave@example.com\", age=28))\n            await session.update_where(\n                User,\n                {\"age\": 29},\n                where=C.eq(\"email\", \"dave@example.com\"),\n            )\n\n        rows = await session.list(User, order_by=[OrderBy(\"id\")])\n        print(\"After committed async transaction:\", rows)\n\n        try:\n            async with session.begin():\n                await session.insert(User(email=\"rollback-async@example.com\", age=77))\n                raise RuntimeError(\"force async rollback\")\n        except RuntimeError:\n            print(\"Async rollback transaction executed as expected.\")\n\n        print(\"Count after async rollback:\", await session.count(User))\n    finally:\n        conn.close()\n\n\ndef main() -> None:\n    sync_demo()\n    asyncio.run(async_demo())\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/sql/18_outbox_pattern.py": "\"\"\"Outbox pattern demo with transaction-scoped session.\"\"\"\n\nfrom __future__ import annotations\n\nimport sqlite3\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\nfrom typing import Any, Optional\n\nfrom mini_orm import C, Database, OrderBy, Session, SQLiteDialect\n\n\n@dataclass\nclass OrderRow:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    customer_email: str = \"\"\n    total_cents: int = 0\n    status: str = \"created\"\n\n\n@dataclass\nclass OutboxMessage:\n    id: Optional[int] = field(default=None, metadata={\"pk\": True, \"auto\": True})\n    aggregate_type: str = \"\"\n    aggregate_id: str = \"\"\n    event_type: str = \"\"\n    payload: dict[str, Any] = field(default_factory=dict)\n    status: str = \"pending\"\n    published_at: Optional[str] = None\n\n\ndef place_order(session: Session, *, email: str, total_cents: int) -> OrderRow:\n    with session.begin():\n        order = session.insert(\n            OrderRow(\n                customer_email=email,\n                total_cents=total_cents,\n                status=\"created\",\n            )\n        )\n        session.insert(\n            OutboxMessage(\n                aggregate_type=\"order\",\n                aggregate_id=str(order.id),\n                event_type=\"order.created\",\n                payload={\n                    \"order_id\": order.id,\n                    \"customer_email\": email,\n                    \"total_cents\": total_cents,\n                },\n            )\n        )\n    return order\n\n\ndef place_order_with_failure(session: Session) -> None:\n    try:\n        with session.begin():\n            order = session.insert(\n                OrderRow(\n                    customer_email=\"rollback@example.com\",\n                    total_cents=9999,\n                )\n            )\n            session.insert(\n                OutboxMessage(\n                    aggregate_type=\"order\",\n                    aggregate_id=str(order.id),\n                    event_type=\"order.created\",\n                    payload={\"order_id\": order.id},\n                )\n            )\n            raise RuntimeError(\"simulated failure before commit\")\n    except RuntimeError as exc:\n        print(\"Expected rollback:\", exc)\n\n\ndef publish_pending_messages(session: Session) -> None:\n    pending = session.list(\n        OutboxMessage,\n        where=C.eq(\"status\", \"pending\"),\n        order_by=[OrderBy(\"id\")],\n    )\n    for message in pending:\n        print(\"Publishing:\", message.event_type, message.payload)\n        with session.begin():\n            session.update_where(\n                OutboxMessage,\n                {\n                    \"status\": \"published\",\n                    \"published_at\": datetime.now(timezone.utc).isoformat(),\n                },\n                where=C.eq(\"id\", message.id),\n            )\n\n\ndef main() -> None:\n    conn = sqlite3.connect(\":memory:\")\n    try:\n        db = Database(conn, SQLiteDialect())\n        session = Session(db, auto_schema=True)\n\n        order_1 = place_order(session, email=\"alice@example.com\", total_cents=1599)\n        order_2 = place_order(session, email=\"bob@example.com\", total_cents=2499)\n        place_order_with_failure(session)\n\n        print(\"Orders persisted:\", session.count(OrderRow))\n        print(\n            \"Pending outbox before publish:\",\n            session.count(OutboxMessage, where=C.eq(\"status\", \"pending\")),\n        )\n        print(\"Created orders:\", order_1, order_2)\n\n        publish_pending_messages(session)\n\n        print(\n            \"Pending outbox after publish:\",\n            session.count(OutboxMessage, where=C.eq(\"status\", \"pending\")),\n        )\n        print(\n            \"Published outbox messages:\",\n            session.count(OutboxMessage, where=C.eq(\"status\", \"published\")),\n        )\n    finally:\n        conn.close()\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/vector/01_inmemory_basic.py": "\"\"\"Basic vector flow with InMemoryVectorStore.\"\"\"\n\nfrom __future__ import annotations\n\nfrom mini_orm import InMemoryVectorStore, VectorMetric, VectorRecord, VectorRepository\n\ndef main() -> None:\n    # Create in-memory store and repository.\n    store = InMemoryVectorStore()\n    repo = VectorRepository(\n        store,\n        \"users\",\n        dimension=3,\n        metric=VectorMetric.COSINE,\n        auto_create=True,\n    )\n\n    # Upsert records (insert new and update existing by ID).\n    repo.upsert(\n        [\n            VectorRecord(id=\"u1\", vector=[1.0, 0.0, 0.0], payload={\"group\": \"a\"}),\n            VectorRecord(id=\"u2\", vector=[0.0, 1.0, 0.0], payload={\"group\": \"b\"}),\n            VectorRecord(id=\"u3\", vector=[0.9, 0.1, 0.0], payload={\"group\": \"a\"}),\n        ]\n    )\n\n    print(\"All records:\", repo.fetch())\n    print(\"Selected records:\", repo.fetch(ids=[\"u2\", \"u1\", \"missing\"]))\n\n    # Query nearest vectors.\n    print(\"Top 2 for [1,0,0]:\", repo.query([1.0, 0.0, 0.0], top_k=2))\n\n    # Filter by payload equality.\n    print(\n        \"Filtered by payload group=a:\",\n        repo.query([1.0, 0.0, 0.0], top_k=5, filters={\"group\": \"a\"}),\n    )\n\n    # Delete by IDs; return count of deleted rows.\n    deleted = repo.delete([\"u2\", \"missing\"])\n    print(\"Deleted count:\", deleted)\n    print(\"Remaining records:\", repo.fetch())\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/vector/02_inmemory_metrics_and_filters.py": "\"\"\"In-memory vector metric behavior and filter examples.\"\"\"\n\nfrom __future__ import annotations\n\nfrom mini_orm import InMemoryVectorStore, VectorMetric, VectorRecord, VectorRepository\n\ndef metric_demo(metric: VectorMetric) -> None:\n    # Each metric can produce different ranking for the same vectors.\n    store = InMemoryVectorStore()\n    repo = VectorRepository(store, f\"metric_{metric.value}\", dimension=2, metric=metric)\n\n    repo.upsert(\n        [\n            VectorRecord(\"a\", [1.0, 0.0], {\"kind\": \"alpha\"}),\n            VectorRecord(\"b\", [2.0, 0.0], {\"kind\": \"beta\"}),\n            VectorRecord(\"c\", [0.0, 1.0], {\"kind\": \"alpha\"}),\n        ]\n    )\n\n    hits = repo.query([1.0, 0.0], top_k=3)\n    print(f\"Metric={metric.value} -> order={[hit.id for hit in hits]}\")\n\ndef filter_demo() -> None:\n    store = InMemoryVectorStore()\n    repo = VectorRepository(store, \"filters\", dimension=3, metric=VectorMetric.COSINE)\n    repo.upsert(\n        [\n            VectorRecord(\"u1\", [1.0, 0.0, 0.0], {\"team\": \"red\", \"level\": 1}),\n            VectorRecord(\"u2\", [0.9, 0.1, 0.0], {\"team\": \"red\", \"level\": 2}),\n            VectorRecord(\"u3\", [0.0, 1.0, 0.0], {\"team\": \"blue\", \"level\": 1}),\n        ]\n    )\n\n    # Exact equality filters over payload.\n    red_hits = repo.query([1.0, 0.0, 0.0], top_k=5, filters={\"team\": \"red\"})\n    red_level_1 = repo.query(\n        [1.0, 0.0, 0.0],\n        top_k=5,\n        filters={\"team\": \"red\", \"level\": 1},\n    )\n\n    # top_k <= 0 returns [] by design.\n    empty_hits = repo.query([1.0, 0.0, 0.0], top_k=0)\n\n    print(\"Filter team=red ->\", [h.id for h in red_hits])\n    print(\"Filter team=red, level=1 ->\", [h.id for h in red_level_1])\n    print(\"top_k=0 ->\", empty_hits)\n\ndef main() -> None:\n    metric_demo(VectorMetric.COSINE)\n    metric_demo(VectorMetric.DOT)\n    metric_demo(VectorMetric.L2)\n    filter_demo()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/vector/03_repository_lifecycle_and_errors.py": "\"\"\"VectorRepository lifecycle and expected error cases.\"\"\"\n\nfrom __future__ import annotations\n\nfrom mini_orm import InMemoryVectorStore, VectorIdPolicy, VectorRecord, VectorRepository\n\ndef expect_error(label: str, fn) -> None:  # noqa: ANN001\n    try:\n        fn()\n    except Exception as exc:  # noqa: BLE001\n        print(f\"[OK] {label}: {type(exc).__name__}: {exc}\")\n    else:\n        print(f\"[UNEXPECTED] {label}: no exception raised\")\n\ndef lifecycle_demo() -> None:\n    store = InMemoryVectorStore()\n\n    # auto_create=False means collection is not created until create_collection().\n    repo = VectorRepository(store, \"lazy_collection\", dimension=2, auto_create=False)\n    expect_error(\"upsert before create_collection\", lambda: repo.upsert([VectorRecord(\"x\", [1, 0])]))\n\n    repo.create_collection()\n    repo.upsert([VectorRecord(\"x\", [1, 0], {\"source\": \"manual_create\"})])\n    print(\"After manual create:\", repo.fetch())\n\n    # overwrite=True recreates collection and clears previous records.\n    recreated = VectorRepository(\n        store,\n        \"lazy_collection\",\n        dimension=2,\n        auto_create=True,\n        overwrite=True,\n    )\n    print(\"After overwrite recreate:\", recreated.fetch())\n\ndef validation_demo() -> None:\n    repo = VectorRepository(InMemoryVectorStore(), \"dim_case\", dimension=2, auto_create=True)\n    expect_error(\"dimension mismatch on upsert\", lambda: repo.upsert([VectorRecord(\"bad\", [1, 0, 0])]))\n    expect_error(\"dimension mismatch on query\", lambda: repo.query([1, 0, 0], top_k=1))\n\ndef filter_capability_demo() -> None:\n    class NoFilterStore(InMemoryVectorStore):\n        supports_filters = False\n\n    repo = VectorRepository(NoFilterStore(), \"no_filters\", dimension=2, auto_create=True)\n    repo.upsert([VectorRecord(\"r1\", [1, 0], {\"group\": \"a\"})])\n    expect_error(\n        \"query with filters on unsupported backend\",\n        lambda: repo.query([1, 0], top_k=1, filters={\"group\": \"a\"}),\n    )\n\ndef id_policy_demo() -> None:\n    class UUIDOnlyStore(InMemoryVectorStore):\n        id_policy = VectorIdPolicy.UUID\n\n    repo = VectorRepository(UUIDOnlyStore(), \"uuid_only\", dimension=2, auto_create=True)\n    expect_error(\"upsert invalid UUID id\", lambda: repo.upsert([VectorRecord(\"not-a-uuid\", [1, 0])]))\n    expect_error(\"fetch invalid UUID id\", lambda: repo.fetch(ids=[\"not-a-uuid\"]))\n    expect_error(\"delete invalid UUID id\", lambda: repo.delete([\"not-a-uuid\"]))\n\ndef main() -> None:\n    lifecycle_demo()\n    validation_demo()\n    filter_capability_demo()\n    id_policy_demo()\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/vector/04_qdrant_example.py": "\"\"\"Qdrant adapter example (optional dependency).\"\"\"\n\nfrom __future__ import annotations\n\nfrom mini_orm import QdrantVectorStore, VectorMetric, VectorRecord, VectorRepository\n\ndef main() -> None:\n    try:\n        # location=\":memory:\" keeps everything in-process for easy local demo.\n        store = QdrantVectorStore(location=\":memory:\")\n    except ImportError as exc:\n        print(\"Qdrant example skipped:\", exc)\n        print(\"Install dependency: pip install qdrant-client\")\n        return\n\n    repo = VectorRepository(\n        store,\n        \"qdrant_users\",\n        dimension=3,\n        metric=VectorMetric.COSINE,\n        auto_create=True,\n        overwrite=True,\n    )\n\n    # Qdrant requires UUID string IDs.\n    u1 = \"11111111-1111-1111-1111-111111111111\"\n    u2 = \"22222222-2222-2222-2222-222222222222\"\n    u3 = \"33333333-3333-3333-3333-333333333333\"\n\n    repo.upsert(\n        [\n            VectorRecord(u1, [1.0, 0.0, 0.0], {\"group\": \"a\"}),\n            VectorRecord(u2, [0.0, 1.0, 0.0], {\"group\": \"b\"}),\n            VectorRecord(u3, [0.9, 0.1, 0.0], {\"group\": \"a\"}),\n        ]\n    )\n\n    print(\"Fetch by IDs:\", repo.fetch(ids=[u2, u1]))\n    print(\"Top hits:\", repo.query([1.0, 0.0, 0.0], top_k=2))\n    print(\n        \"Filtered hits group=a:\",\n        repo.query([1.0, 0.0, 0.0], top_k=5, filters={\"group\": \"a\"}),\n    )\n\n    deleted = repo.delete([u2, \"44444444-4444-4444-4444-444444444444\"])\n    print(\"Deleted count:\", deleted)\n    print(\"Remaining:\", repo.fetch())\n\n    # Example validation: invalid UUID should raise ValueError.\n    try:\n        repo.upsert([VectorRecord(\"not-a-uuid\", [1.0, 0.0, 0.0], {\"group\": \"x\"})])\n    except ValueError as exc:\n        print(\"Expected UUID policy error:\", exc)\n\n    # For persistent local storage, use for example:\n    # store = QdrantVectorStore(location=\"./.qdrant\")\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/vector/05_chroma_example.py": "\"\"\"Chroma adapter example (optional dependency).\"\"\"\n\nfrom __future__ import annotations\n\nfrom mini_orm import ChromaVectorStore, VectorMetric, VectorRecord, VectorRepository\n\ndef metric_preview(metric: VectorMetric) -> None:\n    store = ChromaVectorStore(path=\":memory:\")\n    repo = VectorRepository(\n        store,\n        f\"chroma_metric_{metric.value}\",\n        dimension=2,\n        metric=metric,\n        auto_create=True,\n        overwrite=True,\n    )\n    repo.upsert(\n        [\n            VectorRecord(\"a\", [1.0, 0.0], {\"kind\": \"a\"}),\n            VectorRecord(\"b\", [2.0, 0.0], {\"kind\": \"b\"}),\n            VectorRecord(\"c\", [0.0, 1.0], {\"kind\": \"c\"}),\n        ]\n    )\n    print(f\"Metric={metric.value} ->\", [hit.id for hit in repo.query([1.0, 0.0], top_k=3)])\n\ndef main() -> None:\n    try:\n        # path=\":memory:\" uses EphemeralClient in this adapter.\n        store = ChromaVectorStore(path=\":memory:\")\n    except ImportError as exc:\n        print(\"Chroma example skipped:\", exc)\n        print(\"Install dependency: pip install chromadb\")\n        return\n\n    repo = VectorRepository(\n        store,\n        \"chroma_users\",\n        dimension=3,\n        metric=VectorMetric.COSINE,\n        auto_create=True,\n        overwrite=True,\n    )\n\n    repo.upsert(\n        [\n            VectorRecord(\"u1\", [1.0, 0.0, 0.0], {\"group\": \"a\"}),\n            VectorRecord(\"u2\", [0.0, 1.0, 0.0], {\"group\": \"b\"}),\n            VectorRecord(\"u3\", [0.9, 0.1, 0.0], {\"group\": \"a\"}),\n            # payload=None is also supported by this adapter.\n            VectorRecord(\"u4\", [0.8, 0.2, 0.0], None),\n        ]\n    )\n\n    print(\"Fetch by IDs:\", repo.fetch(ids=[\"u2\", \"u1\"]))\n    print(\"Top hits:\", repo.query([1.0, 0.0, 0.0], top_k=3))\n    print(\n        \"Filtered hits group=a:\",\n        repo.query([1.0, 0.0, 0.0], top_k=5, filters={\"group\": \"a\"}),\n    )\n\n    deleted = repo.delete([\"u2\", \"missing\"])\n    print(\"Deleted count:\", deleted)\n    print(\"Remaining:\", repo.fetch())\n\n    # Optional metric demos.\n    metric_preview(VectorMetric.DOT)\n    metric_preview(VectorMetric.L2)\n\n    # For persistent local storage:\n    # persistent_store = ChromaVectorStore(path=\"./.chroma\")\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/vector/06_faiss_example.py": "\"\"\"Faiss adapter example (optional dependency).\"\"\"\n\nfrom __future__ import annotations\n\nfrom mini_orm import FaissVectorStore, VectorMetric, VectorRecord, VectorRepository\n\ndef metric_preview(metric: VectorMetric) -> None:\n    store = FaissVectorStore()\n    repo = VectorRepository(\n        store,\n        f\"faiss_metric_{metric.value}\",\n        dimension=2,\n        metric=metric,\n        auto_create=True,\n        overwrite=True,\n    )\n    repo.upsert(\n        [\n            VectorRecord(\"a\", [1.0, 0.0]),\n            VectorRecord(\"b\", [2.0, 0.0]),\n            VectorRecord(\"c\", [0.0, 1.0]),\n        ]\n    )\n    print(f\"Metric={metric.value} ->\", [hit.id for hit in repo.query([1.0, 0.0], top_k=3)])\n\ndef main() -> None:\n    try:\n        store = FaissVectorStore()\n    except ImportError as exc:\n        print(\"Faiss example skipped:\", exc)\n        print(\"Install dependency: pip install faiss-cpu numpy\")\n        return\n\n    repo = VectorRepository(\n        store,\n        \"faiss_users\",\n        dimension=3,\n        metric=VectorMetric.COSINE,\n        auto_create=True,\n        overwrite=True,\n    )\n\n    repo.upsert(\n        [\n            VectorRecord(\"u1\", [1.0, 0.0, 0.0], {\"group\": \"a\"}),\n            VectorRecord(\"u2\", [0.0, 1.0, 0.0], {\"group\": \"b\"}),\n            VectorRecord(\"u3\", [0.9, 0.1, 0.0], {\"group\": \"a\"}),\n        ]\n    )\n\n    print(\"Fetch by IDs:\", repo.fetch(ids=[\"u2\", \"u1\"]))\n    print(\"Top hits:\", repo.query([1.0, 0.0, 0.0], top_k=2))\n\n    deleted = repo.delete([\"u2\", \"missing\"])\n    print(\"Deleted count:\", deleted)\n    print(\"Remaining:\", repo.fetch())\n\n    # Faiss adapter does not support payload filters.\n    try:\n        repo.query([1.0, 0.0, 0.0], top_k=1, filters={\"group\": \"a\"})\n    except NotImplementedError as exc:\n        print(\"Expected filter unsupported error:\", exc)\n\n    # Optional metric demos.\n    metric_preview(VectorMetric.DOT)\n    metric_preview(VectorMetric.L2)\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/vector/07_payload_codec.py": "\"\"\"Vector payload codec example (serialize/deserialize for metadata).\"\"\"\n\nfrom __future__ import annotations\n\nfrom enum import Enum\n\nfrom mini_orm import (\n    InMemoryVectorStore,\n    JsonVectorPayloadCodec,\n    VectorRecord,\n    VectorRepository,\n)\n\nclass Status(str, Enum):\n    ACTIVE = \"active\"\n    INACTIVE = \"inactive\"\n\ndef main() -> None:\n    store = InMemoryVectorStore()\n    repo = VectorRepository(\n        store,\n        \"users\",\n        dimension=2,\n        payload_codec=JsonVectorPayloadCodec(),\n    )\n\n    repo.upsert(\n        [\n            VectorRecord(\n                id=\"u1\",\n                vector=[1.0, 0.0],\n                payload={\"status\": Status.ACTIVE, \"profile\": {\"tier\": \"gold\"}},\n            ),\n            VectorRecord(\n                id=\"u2\",\n                vector=[0.0, 1.0],\n                payload={\"status\": Status.INACTIVE, \"profile\": {\"tier\": \"silver\"}},\n            ),\n        ]\n    )\n\n    raw = store.fetch(\"users\", ids=[\"u1\"])[0]\n    print(\"Raw backend payload:\", raw.payload)\n\n    loaded = repo.fetch(ids=[\"u1\"])[0]\n    print(\"Decoded payload:\", loaded.payload)\n    print(\"Decoded status type:\", type(loaded.payload[\"status\"]).__name__)\n\n    filtered = repo.query([1.0, 0.0], top_k=5, filters={\"status\": Status.ACTIVE})\n    print(\"Filter by enum status:\", [item.id for item in filtered])\n\nif __name__ == \"__main__\":\n    main()\n",
  "examples/vector/08_async_inmemory_basic.py": "\"\"\"Async in-memory vector repository example.\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\n\nfrom mini_orm import AsyncVectorRepository, InMemoryVectorStore, VectorRecord\n\nasync def main() -> None:\n    store = InMemoryVectorStore()\n    repo = AsyncVectorRepository(store, \"items\", dimension=3)\n\n    await repo.upsert(\n        [\n            VectorRecord(id=\"1\", vector=[0.1, 0.2, 0.3], payload={\"group\": \"a\"}),\n            VectorRecord(id=\"2\", vector=[0.9, 0.1, 0.0], payload={\"group\": \"b\"}),\n        ]\n    )\n    hits = await repo.query([0.1, 0.2, 0.25], top_k=2)\n    print(\"hits:\", hits)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
  "examples/vector/09_async_qdrant_example.py": "\"\"\"Async Qdrant adapter example (optional dependency).\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\n\nfrom mini_orm import (\n    AsyncVectorRepository,\n    QdrantVectorStore,\n    VectorMetric,\n    VectorRecord,\n)\n\nasync def main() -> None:\n    try:\n        # location=\":memory:\" keeps everything in-process for easy local demo.\n        store = QdrantVectorStore(location=\":memory:\")\n    except ImportError as exc:\n        print(\"Qdrant async example skipped:\", exc)\n        print(\"Install dependency: pip install qdrant-client\")\n        return\n\n    repo = AsyncVectorRepository(\n        store,\n        \"qdrant_async_users\",\n        dimension=3,\n        metric=VectorMetric.COSINE,\n        auto_create=True,\n        overwrite=True,\n    )\n\n    # Qdrant requires UUID string IDs.\n    u1 = \"11111111-1111-1111-1111-111111111111\"\n    u2 = \"22222222-2222-2222-2222-222222222222\"\n    u3 = \"33333333-3333-3333-3333-333333333333\"\n\n    await repo.upsert(\n        [\n            VectorRecord(u1, [1.0, 0.0, 0.0], {\"group\": \"a\"}),\n            VectorRecord(u2, [0.0, 1.0, 0.0], {\"group\": \"b\"}),\n            VectorRecord(u3, [0.9, 0.1, 0.0], {\"group\": \"a\"}),\n        ]\n    )\n\n    print(\"Fetch by IDs:\", await repo.fetch(ids=[u2, u1]))\n    print(\"Top hits:\", await repo.query([1.0, 0.0, 0.0], top_k=2))\n    print(\n        \"Filtered hits group=a:\",\n        await repo.query([1.0, 0.0, 0.0], top_k=5, filters={\"group\": \"a\"}),\n    )\n\n    deleted = await repo.delete([u2, \"44444444-4444-4444-4444-444444444444\"])\n    print(\"Deleted count:\", deleted)\n    print(\"Remaining:\", await repo.fetch())\n\n    try:\n        await repo.upsert([VectorRecord(\"not-a-uuid\", [1.0, 0.0, 0.0], {\"group\": \"x\"})])\n    except ValueError as exc:\n        print(\"Expected UUID policy error:\", exc)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
  "examples/vector/10_async_chroma_example.py": "\"\"\"Async Chroma adapter example (optional dependency).\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\n\nfrom mini_orm import (\n    AsyncVectorRepository,\n    ChromaVectorStore,\n    VectorMetric,\n    VectorRecord,\n)\n\nasync def metric_preview(metric: VectorMetric) -> None:\n    \"\"\"Preview ranking metric behavior.\n\n    Requires `ChromaVectorStore` dependency (`chromadb`) to be importable;\n    otherwise constructing the store raises `ImportError`.\n    \"\"\"\n    store = ChromaVectorStore(path=\":memory:\")\n    repo = AsyncVectorRepository(\n        store,\n        f\"chroma_async_metric_{metric.value}\",\n        dimension=2,\n        metric=metric,\n        auto_create=True,\n        overwrite=True,\n    )\n    await repo.upsert(\n        [\n            VectorRecord(\"a\", [1.0, 0.0], {\"kind\": \"a\"}),\n            VectorRecord(\"b\", [2.0, 0.0], {\"kind\": \"b\"}),\n            VectorRecord(\"c\", [0.0, 1.0], {\"kind\": \"c\"}),\n        ]\n    )\n    hits = await repo.query([1.0, 0.0], top_k=3)\n    print(f\"Metric={metric.value} ->\", [hit.id for hit in hits])\n\nasync def main() -> None:\n    try:\n        store = ChromaVectorStore(path=\":memory:\")\n    except ImportError as exc:\n        print(\"Chroma async example skipped:\", exc)\n        print(\"Install dependency: pip install chromadb\")\n        return\n\n    repo = AsyncVectorRepository(\n        store,\n        \"chroma_async_users\",\n        dimension=3,\n        metric=VectorMetric.COSINE,\n        auto_create=True,\n        overwrite=True,\n    )\n\n    await repo.upsert(\n        [\n            VectorRecord(\"u1\", [1.0, 0.0, 0.0], {\"group\": \"a\"}),\n            VectorRecord(\"u2\", [0.0, 1.0, 0.0], {\"group\": \"b\"}),\n            VectorRecord(\"u3\", [0.9, 0.1, 0.0], {\"group\": \"a\"}),\n            VectorRecord(\"u4\", [0.8, 0.2, 0.0], None),\n        ]\n    )\n\n    print(\"Fetch by IDs:\", await repo.fetch(ids=[\"u2\", \"u1\"]))\n    print(\"Top hits:\", await repo.query([1.0, 0.0, 0.0], top_k=3))\n    print(\n        \"Filtered hits group=a:\",\n        await repo.query([1.0, 0.0, 0.0], top_k=5, filters={\"group\": \"a\"}),\n    )\n\n    deleted = await repo.delete([\"u2\", \"missing\"])\n    print(\"Deleted count:\", deleted)\n    print(\"Remaining:\", await repo.fetch())\n\n    await metric_preview(VectorMetric.DOT)\n    await metric_preview(VectorMetric.L2)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
  "examples/vector/11_async_faiss_example.py": "\"\"\"Async Faiss adapter example (optional dependency).\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\n\nfrom mini_orm import AsyncVectorRepository, FaissVectorStore, VectorMetric, VectorRecord\n\nasync def metric_preview(metric: VectorMetric) -> None:\n    \"\"\"Preview metric behavior for `AsyncVectorRepository` with `FaissVectorStore`.\"\"\"\n    try:\n        store = FaissVectorStore()\n    except ImportError as exc:\n        print(\"Faiss metric preview skipped:\", exc)\n        return\n    repo = AsyncVectorRepository(\n        store,\n        f\"faiss_async_metric_{metric.value}\",\n        dimension=2,\n        metric=metric,\n        auto_create=True,\n        overwrite=True,\n    )\n    await repo.upsert(\n        [\n            VectorRecord(\"a\", [1.0, 0.0]),\n            VectorRecord(\"b\", [2.0, 0.0]),\n            VectorRecord(\"c\", [0.0, 1.0]),\n        ]\n    )\n    hits = await repo.query([1.0, 0.0], top_k=3)\n    print(f\"Metric={metric.value} ->\", [hit.id for hit in hits])\n\nasync def main() -> None:\n    try:\n        store = FaissVectorStore()\n    except ImportError as exc:\n        print(\"Faiss async example skipped:\", exc)\n        print(\"Install dependency: pip install faiss-cpu numpy\")\n        return\n\n    repo = AsyncVectorRepository(\n        store,\n        \"faiss_async_users\",\n        dimension=3,\n        metric=VectorMetric.COSINE,\n        auto_create=True,\n        overwrite=True,\n    )\n\n    await repo.upsert(\n        [\n            VectorRecord(\"u1\", [1.0, 0.0, 0.0], {\"group\": \"a\"}),\n            VectorRecord(\"u2\", [0.0, 1.0, 0.0], {\"group\": \"b\"}),\n            VectorRecord(\"u3\", [0.9, 0.1, 0.0], {\"group\": \"a\"}),\n        ]\n    )\n\n    print(\"Fetch by IDs:\", await repo.fetch(ids=[\"u2\", \"u1\"]))\n    print(\"Top hits:\", await repo.query([1.0, 0.0, 0.0], top_k=2))\n\n    deleted = await repo.delete([\"u2\", \"missing\"])\n    print(\"Deleted count:\", deleted)\n    print(\"Remaining:\", await repo.fetch())\n\n    try:\n        await repo.query([1.0, 0.0, 0.0], top_k=1, filters={\"group\": \"a\"})\n    except NotImplementedError as exc:\n        print(\"Expected filter unsupported error:\", exc)\n\n    await metric_preview(VectorMetric.DOT)\n    await metric_preview(VectorMetric.L2)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
  "examples/vector/12_pgvector_example.py": "\"\"\"PgVector adapter example (requires PostgreSQL + pgvector extension).\"\"\"\n\nfrom __future__ import annotations\n\nimport importlib\nimport os\nfrom typing import Any\n\nfrom mini_orm import (\n    Database,\n    PgVectorStore,\n    PostgresDialect,\n    VectorMetric,\n    VectorRecord,\n    VectorRepository,\n)\n\ndef _load_connect() -> Any:\n    for module_name in (\"psycopg\", \"psycopg2\"):\n        try:\n            module = importlib.import_module(module_name)\n        except (ModuleNotFoundError, ImportError):\n            continue\n        connect = getattr(module, \"connect\", None)\n        if connect is not None:\n            return connect\n    return None\n\ndef main() -> None:\n    connect = _load_connect()\n    if connect is None:\n        print(\"PgVector example skipped: psycopg/psycopg2 not installed.\")\n        print(\"Install dependency: pip install psycopg\")\n        return\n\n    password = os.getenv(\n        \"MINI_ORM_PG_PASSWORD\",\n        os.getenv(\"PGPASSWORD\", os.getenv(\"POSTGRES_PASSWORD\", \"password\")),\n    )\n    params = {\n        \"host\": os.getenv(\"MINI_ORM_PG_HOST\", os.getenv(\"PGHOST\", \"localhost\")),\n        \"port\": int(os.getenv(\"MINI_ORM_PG_PORT\", os.getenv(\"PGPORT\", \"5432\"))),\n        \"user\": os.getenv(\"MINI_ORM_PG_USER\", os.getenv(\"PGUSER\", \"postgres\")),\n        \"password\": password,\n        \"dbname\": os.getenv(\"MINI_ORM_PG_DATABASE\", os.getenv(\"PGDATABASE\", \"postgres\")),\n    }\n\n    try:\n        conn = connect(**params)\n    except Exception as exc:  # noqa: BLE001 - pragmatic cross-driver OperationalError handling\n        print(\"PgVector example skipped:\", exc)\n        return\n\n    db = Database(conn, PostgresDialect())\n    try:\n        store = PgVectorStore(db)\n        repo = VectorRepository(\n            store,\n            \"pgvector_users\",\n            dimension=3,\n            metric=VectorMetric.COSINE,\n            auto_create=True,\n            overwrite=True,\n        )\n\n        repo.upsert(\n            [\n                VectorRecord(\"u1\", [1.0, 0.0, 0.0], {\"group\": \"a\"}),\n                VectorRecord(\"u2\", [0.0, 1.0, 0.0], {\"group\": \"b\"}),\n                VectorRecord(\"u3\", [0.9, 0.1, 0.0], {\"group\": \"a\"}),\n            ]\n        )\n\n        print(\"Fetch by IDs:\", repo.fetch(ids=[\"u2\", \"u1\"]))\n        print(\"Top hits:\", repo.query([1.0, 0.0, 0.0], top_k=2))\n        print(\n            \"Filtered:\",\n            repo.query([1.0, 0.0, 0.0], top_k=5, filters={\"group\": \"a\"}),\n        )\n    finally:\n        db.close()\n\nif __name__ == \"__main__\":\n    main()\n"
};
